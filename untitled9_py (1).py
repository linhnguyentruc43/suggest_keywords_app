import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
import glob
# ----- 1. Táº£i dá»¯ liá»‡u chÃ­nh -----
@st.cache_data
def load_data():
    df = pd.read_csv("keywords_sample.csv")
    df = df.dropna(subset=['keyword'])
    df['keyword'] = df['keyword'].astype(str).str.lower()
    return df
df = load_data()
# ----- 2. TÃ¬m táº¥t cáº£ ngÆ°á»i dÃ¹ng tá»« cÃ¡c file lá»‹ch sá»­ -----
def get_all_users():
    files = glob.glob("search_history_*.csv")
    users = [os.path.splitext(os.path.basename(f))[0].replace("search_history_", "") for f in files]
    return sorted(users)
# ----- 3. Giao diá»‡n chá»n ngÆ°á»i dÃ¹ng -----
st.markdown("<h1 style='text-align: center;'>ğŸ” Gá»£i Ã½ tá»« khÃ³a cÃ¡ nhÃ¢n hÃ³a</h1>", unsafe_allow_html=True)
all_users = get_all_users()
new_user_input = st.text_input("ğŸ†• Nháº­p tÃªn ngÆ°á»i dÃ¹ng má»›i náº¿u chÆ°a cÃ³:")
selected_user = None
if new_user_input:
    selected_user = new_user_input.strip().lower()
else:
    if all_users:
        selected_user = st.selectbox("ğŸ‘¤ Chá»n ngÆ°á»i dÃ¹ng Ä‘Ã£ cÃ³:", all_users)
    else:
        st.info("ğŸ”§ ChÆ°a cÃ³ ngÆ°á»i dÃ¹ng nÃ o. Vui lÃ²ng nháº­p tÃªn má»›i.")
if selected_user:
    history_file = f"search_history_{selected_user}.csv"
    def load_user_history(file_path):
        try:
            history_df = pd.read_csv(file_path)
            return " ".join(history_df['keyword'].astype(str).tolist())
        except:
            return ""
    user_history = load_user_history(history_file)
    # ----- TF-IDF model -----
    vectorizer = TfidfVectorizer(stop_words='english')
    vectorizer.fit(df['keyword'])
    def suggest_keywords(input_text, top_n=5):
        personalized_input = input_text + " " + user_history
        input_vec = vectorizer.transform([personalized_input])
        keyword_vecs = vectorizer.transform(df['keyword'])
        cosine_sim = cosine_similarity(input_vec, keyword_vecs).flatten()
        top_indices = cosine_sim.argsort()[::-1][:top_n]
        return df['keyword'].iloc[top_indices]
    # ----- Giao diá»‡n tÃ¬m kiáº¿m -----
    user_input = st.text_input("ğŸ” Nháº­p tá»« khÃ³a báº¡n Ä‘ang tÃ¬m:")
    if user_input:
        suggestions = suggest_keywords(user_input)
        st.markdown("### ğŸ“Œ Gá»£i Ã½ tá»« khÃ³a dÃ nh riÃªng cho báº¡n:")
        for i, keyword in enumerate(suggestions, 1):
            st.write(f"{i}. {keyword}")
        # ----- LÆ°u lá»‹ch sá»­ tÃ¬m kiáº¿m -----
        new_entry = pd.DataFrame({'keyword': [user_input]})
        try:
            history_df = pd.read_csv(history_file)
            updated_df = pd.concat([history_df, new_entry], ignore_index=True)
        except:
            updated_df = new_entry
        updated_df.to_csv(history_file, index=False)
